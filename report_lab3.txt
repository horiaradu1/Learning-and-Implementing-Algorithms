Name: Horia-Gabriel Radu


This file has been provided to help you structure your write-up of Lab 3, Part c. Some questions can be answered with a single sentence, some may require much longer answers. You are free to edit/rearrange this file as much as you want.

All questions should be answered for each of your chosen data structures. 


------------------------
Initial Expectations
------------------------


>> Do you expect this data structure to be preferable to the others on all inputs, most  inputs, some inputs? Why?
    > Darray (Quick Sort) - I think that the dynamic array data structure will be the fastest when the input is already sorted, as we will run the quick sort only once, O(1).
So, the input could play a big part in its performance, sorted, not sorted or the worst case scenario, reverse sorted.
    > Hashset (Linear probing) - I consider that the hashset will not depend a lot on the inputs, but will depend more on the hash table and dictionary size, and how frequent the rehashing is done based on the load factor.
So, if the hash table size is bigger, or not much smaller than the dictionary, it could be preferable in front of the other inputs. But also we will have to take in consideration the performance of the hash function.
    > Bstree - I expect the binary search tree to be pretty random, but average in its performance, for most random input given. But it could also prove to be the most or least preferable in certain scenarios, like a sorted list.
So, the binary search tree preferability could prove to be good as an average of random inputs.

All in all, both dynamic array could be the fastest for a sorted list, which would make the binary search tree the slowest, and hashset medium, depending on its size.
In case the hashtable size is much bigger than the dictionary, thus resulting in little to none rehases, this could prove the fastest.


>> Do you expect your answer to change if the dictionary is in the best/worst case for sorting? Why?
If the dictionary is in the best case for sorting, this might result in the dynamic array being the fastest, cause it needs no more to sort the dictionary.
The exact opposite goes if the dictionary is in the worst case, thus resulting in the dynamic array being the slowest.
For the hashset, I do not think that the sorting of the dictionary will matter at all.
And for the binary search tree, both best and worst dictionary sorts could have a big negative impact in its performance, making it the worst in both cases.


>> Can you phrase what you expect in terms of a one or two sentence hypothesis that you can test?
I will do my best to understand which data structure will work the best on average, with random inputs, and varying cases for sorting.
So this means, that I will know which one will be most preferable to use on what specific occasions.


------------------------
Experimental Design
------------------------


>> How are you going to define what it means for one data structure to be preferable to another?
Preferability will take in consideration each data structure time performance.
This basically means, that the data structure with the least time, will be most preferable.
Also, for the hashset, I will have to make sure that it does not use an insane amount of memory, in the size of the hash table.


>> Which conditions will you vary in your experiment? 
There will be 3 types of inputs, the worst and best case for sorting (sorted and reverse sorted), plus a random sorted case.
I will use the same dictionary size for all these conditions.
The hash function could also have an impact on the Hashset.


>> How will you vary them? Why did you make these choices? Did you use theoretical complexities, best, worst and average cases to inform your decisions?
The worst cases for the data structures are:
Dynamic Array: O(n^2) + O(log(n)) = O(n^2 + log(n)), which is the quick sort worst case plus the binary search worst case, which both can result in a O(1) for a sorted list
Hashset worst case is O(n), with average case O(1)
Binary Search Tree worst case is O(n), with average case O(log(n))
I will vary those complexities by chaning in between the worst and best case for sorting, plus also making a random sorted case.
I made the choice to experiment them in this way based on my knowledge of how Binary Search Trees and Dynamic Arrays work, with different types of inputs.
Furthermore, I presume that the Hashset will be fairly similar for those conditions, and will depend more on the sizes it has assigned.


>> How will you generate the data for your experiments?
Data for this experiment will be generated by the script provided in data/generate.sh, for each sorted, reverse sorted and random dictionaries.
Plus, data/random_strings.py will be used in creating the strings for each dictionary.
The code for generating is:
Sorted: sudo bash generate.sh experiment/dict_strings experiment/sorted/dict experiment/sorted/infile 100000 50000 sorted 100
Reverse sorted: sudo bash generate.sh experiment/dict_strings experiment/r_sorted/dict experiment/r_sorted/infile 100000 50000 reverse 100
Random: sudo bash generate.sh experiment/dict_strings experiment/random/dict experiment/random/infile 100000 50000 random 100
Each dictionary will have 100000 strings, with 50000 queries, and all of them will be in the dictionary.
The strings will be 20 characters long.


>> How will you validate your findings?
I will run each case 3 times, for each data structure, and take the smallest time in each.
If the differences seem to be very big, I will continue running the tests a bit more, and take the average of the results.


------------------------
Results and Analysis
------------------------


>> What results did you record?
Dynamic Array:
    Sorted = 2 minutes and 7.5 seconds but did not finish (Segmentation fault)
    Reverse Sorted = 2 minutes and 1 second but did not finish (Segmentation fault)
    Random = 1.35 seconds
Hashset:
    Sorted = 5.1 seconds
    Reverse Sorted = 4.9 seconds
    Random = 5.1 seconds
Binary Search Tree:
    Sorted = 37.2 seconds but did not finish (Segmentation fault)
    Reverse Sorted = 36.2 seconds but did not finish (Segmentation fault)
    Random = 2.55 seconds (Ran multiple times with different random dictionaries, but seemed to vary a lot by 1 second)

Initially I was surprised by the results of the sorted and reverse sorted Dynamic Array, but I started playing with those dictionaries.
I noticed that if I randomized some values in the dictionaries (almost sort) it would then work, and the time would get lower.
The more and more I "un" sorted those dictionaries, the better the Dynamic Array would perform, with a significantly lower time, close to the time I got in the Random dictionary.


>> What does this tell you about the performance of the data structure?
As expected, the case of the dictionary, whether it was sorted, reverse sorted or random, did not significantly impact the performance of the Hashset.
Also as expected, the binary search tree did not seem to have a good performance at all for sorted or reverse sorted dictionaries, even if it performed nicely for the random dictionary.
What I did not expect was the way the Dynamic Array performed, such that it was almost not even able to get a time for the sorted and reverse sorted cases.
While it did manage to finish the random dictionary fastest out of them all.

>> What is the answer to the question "Under what conditions is it preferable to use this data structure?"
So far, I would say that the hashset is the most preferable data structure out of them all.
This is because it managed to handel all cases of dictionaries.

> One more thing before I make my final decision, is that I want to test a bigger random dictionary for all the data structures, to see how each ones time increases/scales.
I have changed the random dict and infile to be of 500000 length, with 250000
sudo bash generate.sh experiment/dict_strings experiment/random/dict experiment/random/infile 500000 250000 random 100

Random:
    Darray = 10.6 seconds
    Hashset = 40.5 seconds with hash table size being 507
    Hashset = 21.1 seconds with hash table size being 750137, thus no rehashing needed
    Bstree = 21.5 seconds

After this, I can conclude that both Dynamic Array and Hashset data structures can be considered preferable, depending on some conditions.
The Dynamic Array seems to get less preferable as the size of the dictionary increases and can be dragged down by the input.
The Hashset looks like, as long as you allocated enough memory(size), for the dictionary you are dealing with, it will be preferable and will not depend on in input given.
Another thing is that the Hashset preferability can be improved by creating a better hash function for it.
Thus I think the Hashset would be more preferable on the long term rather than the Dynamic Array.